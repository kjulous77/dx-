{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential  # Functional API --> 기능이 많다. 로컬 연결\n",
    "from keras.layers import Dense\n",
    "from keras.backend import clear_session\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://keras.io/examples/vision/knowledge_distillation/#introduction-to-knowledge-distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  # 텐서플로가 첫 번째 GPU에 1GB 메모리만 할당하도록 제한\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(\n",
    "        gpus[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072)])\n",
    "  except RuntimeError as e:\n",
    "    # 프로그램 시작시에 가상 장치가 설정되어야만 합니다\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller(keras.Model):\n",
    "    def __init__(self, student, teacher):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "\n",
    "    def compile(\n",
    "        self,\n",
    "        optimizer,\n",
    "        metrics,\n",
    "        student_loss_fn,\n",
    "        distillation_loss_fn,\n",
    "        alpha=0.1,\n",
    "        temperature=3,\n",
    "    ):\n",
    "        \"\"\" Configure the distiller(증류기 구성)\n",
    "\n",
    "        Args:\n",
    "            optimizer: Keras optimizer for the student weights\n",
    "            metrics: Keras metrics for evaluation\n",
    "            student_loss_fn: Loss function of difference between student\n",
    "                predictions and ground-truth\n",
    "            distillation_loss_fn: Loss function of difference between soft\n",
    "                student predictions and soft teacher predictions\n",
    "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
    "            temperature: Temperature for softening probability distributions.\n",
    "                Larger temperature gives softer distributions.\n",
    "                \n",
    "            1) 옵티마이저 : 학생 가중치를위한 Keras 옵티마이저\n",
    "            2) 메트릭 : 평가를위한 Keras 메트릭\n",
    "            3) student_loss_fn : 학생차의 손실 함수(예측값과 실제값)\n",
    "            4) distillation_loss_fn : 연약한 차이의 손실 함수(소프트학생 예측 및 소프트교사 예측)\n",
    "            5) alpha : student_loss_fn 및 1-alpha to distillation_loss_fn에 대한 가중치\n",
    "            6) 온도 : 확률 분포를 연화시키기 위한 온도(더 큰 온도는 더 부드러운 분포를 제공)\n",
    "            \n",
    "        \"\"\"\n",
    "        super(Distiller, self).compile(optimizer=optimizer, metrics=metrics)\n",
    "        self.student_loss_fn = student_loss_fn\n",
    "        self.distillation_loss_fn = distillation_loss_fn\n",
    "        self.alpha = alpha\n",
    "        self.temperature = temperature\n",
    "\n",
    "    def train_step(self, data):\n",
    "        # Unpack data(데이터 언패킹)\n",
    "        x, y = data\n",
    "\n",
    "        # Forward pass of teacher(교사의 Foward Pass)\n",
    "        teacher_predictions = self.teacher(x, training=False)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward pass of student(학생의 Foward Pass)\n",
    "            student_predictions = self.student(x, training=True)\n",
    "\n",
    "            # Compute losses(Losses 계산)\n",
    "            student_loss = self.student_loss_fn(y, student_predictions)\n",
    "            distillation_loss = self.distillation_loss_fn(\n",
    "                tf.nn.relu(teacher_predictions / self.temperature),\n",
    "                tf.nn.relu(student_predictions / self.temperature),\n",
    "            )\n",
    "            loss = self.alpha * student_loss + (1 - self.alpha) * distillation_loss\n",
    "\n",
    "        # Compute gradients(gradients 계산)\n",
    "        trainable_vars = self.student.trainable_variables\n",
    "        gradients = tape.gradient(loss, trainable_vars)\n",
    "\n",
    "        # Update weights(가중치 업데이트)\n",
    "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
    "\n",
    "        # Update the metrics configured in `compile()`. (컴파일안에서 메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, student_predictions)\n",
    "\n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update(\n",
    "            {\"student_loss\": student_loss, \"distillation_loss\": distillation_loss}\n",
    "        )\n",
    "        return results\n",
    "\n",
    "    def test_step(self, data):\n",
    "        # Unpack the data(데이터 언패킹)\n",
    "        x, y = data\n",
    "\n",
    "        # Compute predictions(예측 수행)\n",
    "        y_prediction = self.student(x, training=False)\n",
    "\n",
    "        # Calculate the loss(loss 계산)\n",
    "        student_loss = self.student_loss_fn(y, y_prediction)\n",
    "\n",
    "        # Update the metrics.(메트릭 업데이트)\n",
    "        self.compiled_metrics.update_state(y, y_prediction)\n",
    "\n",
    "        # Return a dict of performance(퍼포먼스 dictionary 리턴)\n",
    "        results = {m.name: m.result() for m in self.metrics}\n",
    "        results.update({\"student_loss\": student_loss})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://aakashgoel12.medium.com/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1(y_true, y_pred, logs={}): #taken from old keras source code\n",
    "    import keras.backend as K\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    logs[\"f1\"]=f1_val\n",
    "    return f1_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', delimiter=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['ID', 'FH2O', 'FNOX', 'FOPTIMETHGLY', 'FOXID', 'FSO4', 'FTBN', 'FUEL', 'SOOTPERCENTAGE',\n",
    "        'U100', 'U75', 'U50', 'U25', 'U20', 'U14', 'U6', 'U4', 'V100', 'P', 'MO', 'MG']\n",
    "df.drop(col, inplace=True, axis=1)\n",
    "df['COMPONENT_ARBITRARY'] = df['COMPONENT_ARBITRARY'].str[9:]\n",
    "df['COMPONENT_ARBITRARY'] = df['COMPONENT_ARBITRARY'].astype('int64')\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillknn(df):\n",
    "    from sklearn.impute import KNNImputer\n",
    "    imputer = KNNImputer(n_neighbors=5)\n",
    "    knn_df=imputer.fit_transform(df)\n",
    "    knn_df=pd.DataFrame(knn_df, columns=df.columns)\n",
    "    return knn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CD</th>\n",
       "      <td>1394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K</th>\n",
       "      <td>2299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "CD  1394\n",
       "K   2299"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결측치 있는 항만 확인\n",
    "nas =pd.DataFrame(df.isna().sum())\n",
    "nas.loc[nas[0]!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fillknn(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target 확인\n",
    "target = 'Y_LABEL'\n",
    "\n",
    "# 데이터 분리\n",
    "x = df.drop(target, axis = 1)\n",
    "x = x.astype('int64')\n",
    "y = df[target]\n",
    "norm_cols = list(x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가변수화 열 지정\n",
    "dumm_cols = ['COMPONENT_ARBITRARY']\n",
    "\n",
    "# 가변수화\n",
    "x = pd.get_dummies(x, columns = dumm_cols, drop_first=True)\n",
    "x1 = x.copy()\n",
    "# 확인\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['ID', 'FH2O', 'FNOX', 'FOPTIMETHGLY', 'FOXID', 'FSO4', 'FTBN', 'FUEL', 'SOOTPERCENTAGE',\n",
    "        'U100', 'U75', 'U50', 'U25', 'U20', 'U14', 'U6', 'U4', 'V100', 'P', 'MO', 'MG']\n",
    "for i in col:\n",
    "    try:\n",
    "        test.drop(i, inplace=True, axis=1)\n",
    "    except:\n",
    "        col.remove(i)\n",
    "test['COMPONENT_ARBITRARY'] = test['COMPONENT_ARBITRARY'].str[9:]\n",
    "test['COMPONENT_ARBITRARY'] = test['COMPONENT_ARBITRARY'].astype('int64')\n",
    "test.drop_duplicates(inplace=True)\n",
    "\n",
    "# 가변수화 열 지정\n",
    "dumm_cols = ['COMPONENT_ARBITRARY']\n",
    "\n",
    "# 가변수화\n",
    "test = pd.get_dummies(test, columns = dumm_cols, drop_first=True)\n",
    "\n",
    "# 확인\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=x1[list(test.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler.fit_transform(x)\n",
    "x = scaler.fit_transform(x)\n",
    "x1 = scaler.fit_transform(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit_transform(test)\n",
    "test = scaler.fit_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "x1_train, x1_test, y1_train, y1_test = train_test_split(x1, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트 :  (18116, 34) (9866,)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트 : (18116, 34) (18116,)\n",
      "SMOTE 적용 후 값의 분포 :\n",
      " 0.0    9058\n",
      "1.0    9058\n",
      "Name: Y_LABEL, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "x_train, y_train_over = smote.fit_resample(x_train, y_train)\n",
    "print(\"SMOTE 적용 전 학습용 피처/레이블 데이터 세트 : \", x_train.shape, y_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트 :', x_train.shape, y_train_over.shape)\n",
    "print('SMOTE 적용 후 값의 분포 :\\n',pd.Series(y_train_over).value_counts() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트 :  (17978, 19) (9866,)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트 : (17978, 19) (17978,)\n",
      "SMOTE 적용 후 값의 분포 :\n",
      " 0.0    8989\n",
      "1.0    8989\n",
      "Name: Y_LABEL, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "x1_train, y1_train_over = smote.fit_resample(x1_train, y1_train)\n",
    "print(\"SMOTE 적용 전 학습용 피처/레이블 데이터 세트 : \", x1_train.shape, y1_train.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트 :', x1_train.shape, y1_train_over.shape)\n",
    "print('SMOTE 적용 후 값의 분포 :\\n',pd.Series(y1_train_over).value_counts() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the teacher # 교사 모델 생성\n",
    "n_features = x_train.shape[1]\n",
    "n_features1 = test.shape[1]\n",
    "teacher = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(128, input_shape = (n_features1, ), activation = 'swish' ),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(64, activation = 'swish' ),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(32, activation = 'swish' ),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ],\n",
    "    name=\"teacher\",\n",
    ")\n",
    "\n",
    "# Create the student # 학생 모델 생성\n",
    "student = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(128, input_shape = (n_features1, ), activation = 'swish' ),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(64, activation = 'swish' ),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(32, activation = 'swish' ),\n",
    "        layers.LeakyReLU(alpha=0.2),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ],\n",
    "    name=\"student\",\n",
    ")\n",
    "\n",
    "# Clone student for later comparison # 후행 비교를 위한 학생 복제\n",
    "student_scratch = keras.models.clone_model(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "562/562 [==============================] - 6s 9ms/step - loss: 0.7784 - get_f1: 0.5168\n",
      "Epoch 2/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.7015 - get_f1: 0.5479\n",
      "Epoch 3/50\n",
      "562/562 [==============================] - 6s 11ms/step - loss: 0.6820 - get_f1: 0.5554\n",
      "Epoch 4/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6794 - get_f1: 0.5684\n",
      "Epoch 5/50\n",
      "562/562 [==============================] - 6s 11ms/step - loss: 0.6753 - get_f1: 0.5829\n",
      "Epoch 6/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6685 - get_f1: 0.6006\n",
      "Epoch 7/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6638 - get_f1: 0.6112\n",
      "Epoch 8/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6561 - get_f1: 0.6223\n",
      "Epoch 9/50\n",
      "562/562 [==============================] - 6s 11ms/step - loss: 0.6524 - get_f1: 0.6341\n",
      "Epoch 10/50\n",
      "562/562 [==============================] - 6s 11ms/step - loss: 0.6493 - get_f1: 0.6421\n",
      "Epoch 11/50\n",
      "562/562 [==============================] - 6s 11ms/step - loss: 0.6425 - get_f1: 0.6482\n",
      "Epoch 12/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6408 - get_f1: 0.6557\n",
      "Epoch 13/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6369 - get_f1: 0.6598\n",
      "Epoch 14/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6369 - get_f1: 0.6603\n",
      "Epoch 15/50\n",
      "562/562 [==============================] - 6s 11ms/step - loss: 0.6354 - get_f1: 0.6594\n",
      "Epoch 16/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6331 - get_f1: 0.6596\n",
      "Epoch 17/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6320 - get_f1: 0.6607\n",
      "Epoch 18/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6302 - get_f1: 0.6647\n",
      "Epoch 19/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6294 - get_f1: 0.6614\n",
      "Epoch 20/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6280 - get_f1: 0.6691\n",
      "Epoch 21/50\n",
      "562/562 [==============================] - 6s 10ms/step - loss: 0.6274 - get_f1: 0.6614\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "133/133 [==============================] - 1s 4ms/step - loss: 0.6643 - get_f1: 0.1629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6642853021621704, 0.16294357180595398]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "# Train teacher as usual # 평소와 같은 방법으로 교사모델 훈련시작\n",
    "teacher.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[get_f1],\n",
    ")\n",
    "\n",
    "# Train and evaluate teacher on data. # 데이터셋을 통해 교사의 트레인 및 평가\n",
    "es = EarlyStopping(monitor='get_f1', min_delta=0, patience=20, verbose=1, restore_best_weights=True)\n",
    "mc = ModelCheckpoint('best_model.h5', monitor='get_f1', mode='max', save_best_only=True)\n",
    "teacher.fit(x1_train, y1_train_over, epochs=50, verbose=1, callbacks=[es, mc])\n",
    "teacher.evaluate(x1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "562/562 [==============================] - 9s 14ms/step - get_f1: 0.5456 - student_loss: 0.6885 - distillation_loss: 0.1961\n",
      "Epoch 2/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.5735 - student_loss: 0.6772 - distillation_loss: 0.1958\n",
      "Epoch 3/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.5740 - student_loss: 0.6733 - distillation_loss: 0.1958\n",
      "Epoch 4/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.5938 - student_loss: 0.6683 - distillation_loss: 0.1959\n",
      "Epoch 5/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6010 - student_loss: 0.6634 - distillation_loss: 0.1960\n",
      "Epoch 6/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6203 - student_loss: 0.6588 - distillation_loss: 0.1962\n",
      "Epoch 7/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6282 - student_loss: 0.6552 - distillation_loss: 0.1963\n",
      "Epoch 8/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6352 - student_loss: 0.6501 - distillation_loss: 0.1964\n",
      "Epoch 9/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6473 - student_loss: 0.6465 - distillation_loss: 0.1965\n",
      "Epoch 10/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6457 - student_loss: 0.6450 - distillation_loss: 0.1966\n",
      "Epoch 11/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6470 - student_loss: 0.6432 - distillation_loss: 0.1966\n",
      "Epoch 12/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6499 - student_loss: 0.6432 - distillation_loss: 0.1966\n",
      "Epoch 13/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6467 - student_loss: 0.6414 - distillation_loss: 0.1966\n",
      "Epoch 14/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6525 - student_loss: 0.6410 - distillation_loss: 0.1967\n",
      "Epoch 15/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6522 - student_loss: 0.6374 - distillation_loss: 0.1967\n",
      "Epoch 16/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6630 - student_loss: 0.6372 - distillation_loss: 0.1968\n",
      "Epoch 17/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6595 - student_loss: 0.6354 - distillation_loss: 0.1968\n",
      "Epoch 18/50\n",
      "562/562 [==============================] - 7s 13ms/step - get_f1: 0.6551 - student_loss: 0.6356 - distillation_loss: 0.1968\n",
      "Epoch 19/50\n",
      "562/562 [==============================] - 8s 14ms/step - get_f1: 0.6571 - student_loss: 0.6364 - distillation_loss: 0.1968\n",
      "Epoch 20/50\n",
      "562/562 [==============================] - 8s 15ms/step - get_f1: 0.6597 - student_loss: 0.6348 - distillation_loss: 0.1968\n",
      "Epoch 21/50\n",
      "562/562 [==============================] - 9s 16ms/step - get_f1: 0.6592 - student_loss: 0.6328 - distillation_loss: 0.1969\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00021: early stopping\n",
      "133/133 [==============================] - 1s 5ms/step - get_f1: 0.1725 - student_loss: 0.6738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.17247577011585236, 0.8291529417037964]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and compile distiller\n",
    "distiller = Distiller(student=student, teacher=teacher)\n",
    "distiller.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    metrics=[get_f1],\n",
    "    student_loss_fn=keras.losses.BinaryCrossentropy(),\n",
    "    distillation_loss_fn=keras.losses.BinaryCrossentropy(),\n",
    "    alpha=0.1,\n",
    "    temperature=10,\n",
    ")\n",
    "\n",
    "# Distill teacher to student\n",
    "es = EarlyStopping(monitor='get_f1', min_delta=0, patience=20, verbose=1, restore_best_weights=True)\n",
    "distiller.fit(x1_train, y1_train_over, epochs=50, verbose=1, callbacks=[es])\n",
    "\n",
    "# Evaluate student on test dataset\n",
    "distiller.evaluate(x1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = student.predict(test)\n",
    "\n",
    "# np.where ==> 0, 1\n",
    "pred = np.where(pred >= 0.5, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "teacher.save('teacher.h5')\n",
    "student.save('student.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Y_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_0002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_0003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_0004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID  Y_LABEL\n",
       "0  TEST_0000        0\n",
       "1  TEST_0001        0\n",
       "2  TEST_0002        1\n",
       "3  TEST_0003        1\n",
       "4  TEST_0004        1"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission =pd.read_csv('sample_submission.csv')\n",
    "submission['Y_LABEL'] = pred\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('sample_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4060\n",
       "1    1981\n",
       "Name: Y_LABEL, dtype: int64"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['Y_LABEL'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Learn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2fa311b612e41a10fce4fca1f1b7b39453f8a84567865feed747b7a4ea636135"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
